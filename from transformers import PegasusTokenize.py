from transformers import PegasusTokenizer, PegasusForConditionalGeneration

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø­ÙˆÙ„ (Tokenizer)
model_name = "google/pegasus-xsum"
tokenizer = PegasusTokenizer.from_pretrained(model_name)
model = PegasusForConditionalGeneration.from_pretrained(model_name)

def summarize_text(text):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªÙˆÙƒÙ†Ø²
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=1024)

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ø®ÙŠØµ
    summary_ids = model.generate(**inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4)
    
    # ÙÙƒ ØªØ±Ù…ÙŠØ² Ø§Ù„ØªÙ„Ø®ÙŠØµ
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    
    return summary

# ØªØ¬Ø±Ø¨Ø© ØªÙ„Ø®ÙŠØµ Ù†Øµ
text = """
Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ Ø£Ø­Ø¯ Ø£ÙƒØ«Ø± Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ØªØ·ÙˆØ±Ù‹Ø§ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø­ÙŠØ« ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª 
Ù…Ø«Ù„ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©ØŒ ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù…Ø§Ù„ÙŠØ©ØŒ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…. ÙŠØ¹ØªÙ…Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚
Ù„ØªÙ‚Ø¯ÙŠÙ… ØªÙˆÙ‚Ø¹Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ­Ù„ÙˆÙ„ ÙØ¹Ø§Ù„Ø©.
"""
summary = summarize_text(text)
print("ğŸ”¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:\n", text)
print("\nğŸ”¹ Ø§Ù„ØªÙ„Ø®ÙŠØµ:\n", summary)
